{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Training File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os, random\n",
    "RAW_JSON_PATH = os.path.expanduser(\"~/autodl-tmp/LEVIR-MCI-dataset/LevirCCcaptions-v2.json\")\n",
    "\n",
    "with open(RAW_JSON_PATH, \"r\") as f: \n",
    "    raw_captions = json.load(f)\n",
    "\n",
    "raw_captions = [row for row in raw_captions if row['filepath'] == \"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "instructs = []\n",
    "lenList = []\n",
    "global_id = 0\n",
    "for img in raw_captions:\n",
    "    # 1）简单描述\n",
    "    for cap in img['sentences']:\n",
    "        rslt = {\n",
    "            'id': global_id,\n",
    "            'image': [f\"{img['filepath']}/A/{img['filename']}\", f\"{img['filepath']}/B/{img['filename']}\"],\n",
    "            'changeflag': img['changeflag'],\n",
    "            'conversations': []\n",
    "            }\n",
    "        rslt['conversations'].extend([\n",
    "            {\n",
    "                \"from\": \"human\",\n",
    "                \"value\": \"<image> Please describe the changes of these two images in detail.\"\n",
    "            },\n",
    "            {\n",
    "                \"from\": \"gpt\",\n",
    "                \"value\": cap.strip().replace(\" .\", \".\")\n",
    "            }\n",
    "        ]\n",
    "        )\n",
    "        instructs.append(rslt)\n",
    "        global_id += 1\n",
    "\n",
    "    # 2）判断是否有变化\n",
    "    rslt = {\n",
    "        'id': global_id,\n",
    "        'image': [f\"{img['filepath']}/A/{img['filename']}\", f\"{img['filepath']}/B/{img['filename']}\"],\n",
    "        'conversations': []\n",
    "        }\n",
    "    rslt['conversations'].extend([\n",
    "        {\n",
    "            \"from\": \"human\",\n",
    "            \"value\": \"<image> <image> Please judge whether these two images have changed. Please answer yes or no.\"\n",
    "        },\n",
    "        {\n",
    "            \"from\": \"gpt\",\n",
    "            \"value\": \"Yes\" if img['changeflag'] == 1 else \"No\"\n",
    "        }\n",
    "    ]\n",
    "    )\n",
    "\n",
    "    instructs.append(rslt)\n",
    "    global_id += 1\n",
    "\n",
    "    # 3）判断变化的类别和数量\n",
    "    rslt = {\n",
    "        'id': global_id,\n",
    "        'image': [f\"{img['filepath']}/A/{img['filename']}\", f\"{img['filepath']}/B/{img['filename']}\"],\n",
    "        'conversations': []\n",
    "        }\n",
    "    \n",
    "    def getNumAnswer(row):\n",
    "        ans = []\n",
    "        road_count = row['change_counts']['road']\n",
    "        building_count = row['change_counts']['building']\n",
    "        if road_count == 0 or row['changeflag'] == 0 :\n",
    "            ans = \"No roads has changed, \"\n",
    "        elif road_count == 1:\n",
    "            ans = \"1 road has changed, \"\n",
    "        else:\n",
    "            ans = f\"{road_count} roads has changed, \"\n",
    "\n",
    "        if building_count == 0 or row['changeflag'] == 0:\n",
    "            ans += \"and no buildings has changed.\"\n",
    "        elif building_count == 1:\n",
    "            ans += \"and 1 building has changed.\"\n",
    "        else:\n",
    "            ans += f\"and {building_count} buildings has changed.\"\n",
    "        return ans\n",
    "\n",
    "    rslt['conversations'].extend([\n",
    "        {\n",
    "            \"from\": \"human\",\n",
    "            \"value\": \"<image> <image> Please determine whether roads and buildings have changed, and count the number of objects in each category that have changed.\"\n",
    "        },\n",
    "        {\n",
    "            \"from\": \"gpt\",\n",
    "            \"value\": getNumAnswer(img)\n",
    "        }\n",
    "    ]\n",
    "    )\n",
    "    instructs.append(rslt)\n",
    "    global_id += 1\n",
    "\n",
    "    # # 4）判断变化目标的轮廓\n",
    "    # rslt = {\n",
    "    #     'id': global_id,\n",
    "    #     'image': [f\"{img['filepath']}/A/{img['filename']}\", f\"{img['filepath']}/B/{img['filename']}\"],\n",
    "    #     'conversations': []\n",
    "    #     }\n",
    "    \n",
    "    # def getCounterAnswer(row):\n",
    "    #     ansList = []\n",
    "    #     for cat, value in row['contours'].items():\n",
    "    #         ansList.append(f\"The contours of the changed {cat}s are:{value}\")\n",
    "    #     ans = \", \".join(ansList) + \".\"\n",
    "    #     lenList.append(len(ans))\n",
    "    #     return ans\n",
    "\n",
    "    # rslt['conversations'].extend([\n",
    "    #     {\n",
    "    #         \"from\": \"human\",\n",
    "    #         \"value\": \"<image> <image> Please draw the outlines of the changed buildings and roads, approximating them with polygons.\"\n",
    "    #     },\n",
    "    #     {\n",
    "    #         \"from\": \"gpt\",\n",
    "    #         \"value\": getCounterAnswer(img)\n",
    "    #     }\n",
    "    # ]\n",
    "    # )\n",
    "    # instructs.append(rslt)\n",
    "    # global_id += 1\n",
    "\n",
    "    # 5）多轮对话\n",
    "    rslt = {\n",
    "        'id': global_id,\n",
    "        'image': [f\"{img['filepath']}/A/{img['filename']}\", f\"{img['filepath']}/B/{img['filename']}\"],\n",
    "        'conversations': []\n",
    "        }\n",
    "    \n",
    "    rslt['conversations'].extend([\n",
    "        {\n",
    "            \"from\": \"human\",\n",
    "            \"value\": \"<image> <image> Please judge whether these two images have changed. Please answer yes or no.\"\n",
    "        },\n",
    "        {\n",
    "            \"from\": \"gpt\",\n",
    "            \"value\": \"Yes\" if img['changeflag'] == 1 else \"No\"\n",
    "        },\n",
    "        {\n",
    "            \"from\": \"human\",\n",
    "            \"value\": \"If changes have occurred, count the number of road and building changes separately.\"\n",
    "        },\n",
    "        {\n",
    "            \"from\": \"gpt\",\n",
    "            \"value\": getNumAnswer(img)\n",
    "        },\n",
    "        {\n",
    "            \"from\": \"human\",\n",
    "            \"value\": \"Based on the above analysis, please describe the changes of these two images in detail.\"\n",
    "        },\n",
    "        {\n",
    "            \"from\": \"gpt\",\n",
    "            \"value\": random.choice(img['sentences']).strip().replace(\" .\", \".\")\n",
    "        }\n",
    "    ]\n",
    "    )\n",
    "    instructs.append(rslt)\n",
    "    global_id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/root/autodl-tmp/LEVIR-MCI-dataset/ChangeChat_instruct_60k.json\", \"w\") as f:\n",
    "    json.dump(instructs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "instructs = []\n",
    "global_id = 0\n",
    "for img in raw_captions:\n",
    "    # 2）判断是否有变化\n",
    "    rslt = {\n",
    "        'id': global_id,\n",
    "        'image': [f\"{img['filepath']}/A/{img['filename']}\", f\"{img['filepath']}/B/{img['filename']}\"],\n",
    "        'changeflag': img['changeflag']\n",
    "        }\n",
    "    instructs.append(rslt)\n",
    "    global_id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/root/autodl-tmp/LEVIR-MCI-dataset/ChangeChat_classify.json\", \"w\") as f:\n",
    "    json.dump(instructs, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Benchmark File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os\n",
    "RAW_JSON_PATH = os.path.expanduser(\"~/autodl-tmp/LEVIR-MCI-dataset/LevirCCcaptions-v2.json\")\n",
    "with open(RAW_JSON_PATH, \"r\") as f: \n",
    "    raw_captions = json.load(f)\n",
    "raw_captions = [row for row in raw_captions if row['filepath'] == \"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jsonlines\n",
    "instructs = []\n",
    "global_id = 100001\n",
    "for img in raw_captions:\n",
    "    rslt = {\n",
    "        'question_id': global_id,\n",
    "        'image': [f\"{img['filepath']}/A/{img['filename']}\", f\"{img['filepath']}/B/{img['filename']}\"],\n",
    "        'changeflag': img['changeflag']\n",
    "        }\n",
    "    instructs.append(rslt)\n",
    "    global_id += 1\n",
    "with open(\"/root/autodl-tmp/LEVIR-MCI-dataset/Test_CC_gt.json\", \"w\") as wfd:\n",
    "    json.dump(instructs, wfd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jsonlines\n",
    "instructs = []\n",
    "global_id = 100001\n",
    "for img in raw_captions:\n",
    "    for cap in img['sentences']:\n",
    "        rslt = {\n",
    "            'question_id': global_id,\n",
    "            'image': [f\"{img['filepath']}/A/{img['filename']}\", f\"{img['filepath']}/B/{img['filename']}\"],\n",
    "            'text': \"<image> <image> Please Describe what changes occurred between the two remote sensing images?\",\n",
    "            'changeflag': img['changeflag'],\n",
    "            'category': 'CC'\n",
    "            }\n",
    "        instructs.append(rslt)\n",
    "        global_id += 1\n",
    "        break\n",
    "\n",
    "with jsonlines.open(\"/root/autodl-tmp/LEVIR-MCI-dataset/Test_CC_v3.jsonl\", \"w\") as wfd:\n",
    "    for data in instructs:\n",
    "        wfd.write(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jsonlines\n",
    "instructs = []\n",
    "global_id = 100001\n",
    "for img in raw_captions:\n",
    "    for cap in img['sentences']:\n",
    "        rslt = {\n",
    "            'question_id': global_id,\n",
    "            'image': [f\"{img['filepath']}/A/{img['filename']}\", f\"{img['filepath']}/B/{img['filename']}\"],\n",
    "            'text': \"<image> <image>\\n Have the objects in these two remote sensing images changed? Please answer yes or no.\",\n",
    "            'category': 'CC'\n",
    "            }\n",
    "        instructs.append(rslt)\n",
    "        global_id += 1\n",
    "        break\n",
    "\n",
    "with jsonlines.open(\"/root/autodl-tmp/LEVIR-MCI-dataset/Test_CC_v3_conv_r1.jsonl\", \"w\") as wfd:\n",
    "    for data in instructs:\n",
    "        wfd.write(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
