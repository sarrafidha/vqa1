{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Training File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os, random\n",
    "RAW_JSON_PATH = os.path.expanduser(\"LEVIR-MCI-dataset/LevirCCcaptions-v2.json\")\n",
    "\n",
    "with open(RAW_JSON_PATH, \"r\") as f: \n",
    "    raw_captions = json.load(f)\n",
    "\n",
    "raw_captions = [row for row in raw_captions if row['filepath'] == \"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        content = file.read()\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "collected_Q_for_count = []\n",
    "for img in raw_captions:\n",
    "    if img['changeflag'] == 0:\n",
    "        continue\n",
    "    file_path = f\"count/results/{img['filename'].replace('.png', '.txt')}\"\n",
    "    QA = read_file(file_path).replace('\\n\\n','\\n').split(\"\\n\")\n",
    "    assert(len(QA)==2), file_path\n",
    "    Q = QA[0].replace(\"Question: \", \"\")\n",
    "    collected_Q_for_count.append(Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "collected_Q_for_count = list(set(collected_Q_for_count))\n",
    "collected_Q_for_count = [x for x in collected_Q_for_count if 'road' in x and 'building' in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "instructs = []\n",
    "lenList = []\n",
    "global_id = 0\n",
    "for img in raw_captions:\n",
    "    # 1）简单描述\n",
    "    for cap in img['sentences']:\n",
    "        rslt = {\n",
    "            'id': global_id,\n",
    "            'image': [f\"{img['filepath']}/A/{img['filename']}\", f\"{img['filepath']}/B/{img['filename']}\"],\n",
    "            'changeflag': img['changeflag'],\n",
    "            'conversations': [],\n",
    "            'type': 1\n",
    "            }\n",
    "        rslt['conversations'].extend([\n",
    "            {\n",
    "                \"from\": \"human\",\n",
    "                \"value\": \"<image> <image> Please briefly describe the changes in these two images.\"\n",
    "            },\n",
    "            {\n",
    "                \"from\": \"gpt\",\n",
    "                \"value\": cap.strip().replace(\" .\", \".\").capitalize()\n",
    "            }\n",
    "        ]\n",
    "        )\n",
    "        instructs.append(rslt)\n",
    "        global_id += 1\n",
    "    \n",
    "\n",
    "    # 2）判断是否有变化\n",
    "    rslt = {\n",
    "        'id': global_id,\n",
    "        'image': [f\"{img['filepath']}/A/{img['filename']}\", f\"{img['filepath']}/B/{img['filename']}\"],\n",
    "        'changeflag': img['changeflag'],\n",
    "        'conversations': [],\n",
    "        'type': 2\n",
    "        }\n",
    "    rslt['conversations'].extend([\n",
    "        {\n",
    "            \"from\": \"human\",\n",
    "            \"value\": \"<image> <image> Please judge whether these two images have changed. Please answer yes or no.\"\n",
    "        },\n",
    "        {\n",
    "            \"from\": \"gpt\",\n",
    "            \"value\": \"Yes\" if img['changeflag'] == 1 else \"No\"\n",
    "        }\n",
    "    ]\n",
    "    )\n",
    "\n",
    "    instructs.append(rslt)\n",
    "    global_id += 1\n",
    "\n",
    "    # 3）判断变化的类别和数量\n",
    "    rslt = {\n",
    "        'id': global_id,\n",
    "        'image': [f\"{img['filepath']}/A/{img['filename']}\", f\"{img['filepath']}/B/{img['filename']}\"],\n",
    "        'changeflag': img['changeflag'],\n",
    "        'conversations': [],\n",
    "        'type': 3\n",
    "        }\n",
    "    \n",
    "    def getCountQA(row):\n",
    "        file_path = f\"count/results/{row['filename'].replace('.png', '.txt')}\"\n",
    "        QA = read_file(file_path).replace('\\n\\n','\\n').split(\"\\n\")\n",
    "        assert(len(QA)==2), file_path\n",
    "        Q = '<image> <image> '+ QA[0].replace(\"Question: \", \"\")\n",
    "        A = QA[1].replace(\"Answer: \", \"\")\n",
    "        if row['changeflag'] == 0:\n",
    "            Q = '<image> <image> '+ random.choice(collected_Q_for_count)\n",
    "        return Q, A\n",
    "\n",
    "    rslt['conversations'].extend([\n",
    "        {\n",
    "            \"from\": \"human\",\n",
    "            \"value\": getCountQA(img)[0]\n",
    "        },\n",
    "        {\n",
    "            \"from\": \"gpt\",\n",
    "            \"value\": getCountQA(img)[1]\n",
    "        }\n",
    "    ]\n",
    "    )\n",
    "    instructs.append(rslt)\n",
    "    global_id += 1\n",
    "\n",
    "    # 4）GPT提问对话判断变化目标的轮廓\n",
    "    rslt = {\n",
    "        'id': global_id,\n",
    "        'image': [f\"{img['filepath']}/A/{img['filename']}\", f\"{img['filepath']}/B/{img['filename']}\"],\n",
    "        'conversations': [],\n",
    "        'type': 4\n",
    "        }\n",
    "    \n",
    "    def getCounterAnswer(row):\n",
    "        ansList = []\n",
    "        for cat, value in row['contours'].items():\n",
    "            if row['changeflag'] == 0:\n",
    "                value = []\n",
    "            ansList.append(f\"The contours of the changed {cat}s are:{json.dumps(value, separators=(',', ':'))}\")\n",
    "        ans = \", \".join(ansList) + \".\"\n",
    "        lenList.append(len(ans))\n",
    "        return ans\n",
    "\n",
    "    rslt['conversations'].extend([\n",
    "        {\n",
    "            \"from\": \"human\",\n",
    "            \"value\": \"<image> <image> Please draw the contours of the changed buildings and roads, approximating them with polygons.\"\n",
    "        },\n",
    "        {\n",
    "            \"from\": \"gpt\",\n",
    "            \"value\": getCounterAnswer(img)\n",
    "        }\n",
    "    ]\n",
    "    )\n",
    "    instructs.append(rslt)\n",
    "    global_id += 1\n",
    "\n",
    "    # 5）GPT提问对话\n",
    "    def getConv(row):\n",
    "        rslt = []\n",
    "        file_path = f\"conversation/results/{row['filename'].replace('.png', '.txt')}\"\n",
    "        conv = read_file(file_path).replace('\\n\\n','\\n').strip().split(\"\\n\")\n",
    "        assert(len(conv) % 2 == 0), file_path\n",
    "        for idx in range(len(conv)//2):\n",
    "            Q = conv[2*idx].replace(\"Question: \", \"\")\n",
    "            A = conv[2*idx + 1].replace(\"Answer: \", \"\")\n",
    "            # if \"how many\" in Q or \"how much\" in Q or \" Please answer yes or no.\" in Q:\n",
    "            #     continue\n",
    "            rslt.append([\n",
    "                {\n",
    "                    \"from\": \"human\",\n",
    "                    \"value\": '<image> <image> '+ Q\n",
    "                },\n",
    "                {\n",
    "                    \"from\": \"gpt\",\n",
    "                    \"value\": A\n",
    "                }\n",
    "            ])\n",
    "        return rslt\n",
    "    convs = getConv(img)\n",
    "    for c in convs:\n",
    "        rslt = {\n",
    "            'id': global_id,\n",
    "            'image': [f\"{img['filepath']}/A/{img['filename']}\", f\"{img['filepath']}/B/{img['filename']}\"],\n",
    "            'changeflag': img['changeflag'],\n",
    "            'conversations': [],\n",
    "            'type': 5\n",
    "            }\n",
    "        rslt['conversations'].extend(c)\n",
    "        instructs.append(rslt)\n",
    "        global_id += 1\n",
    "    # 6）多轮对话\n",
    "    rslt = {\n",
    "        'id': global_id,\n",
    "        'image': [f\"{img['filepath']}/A/{img['filename']}\", f\"{img['filepath']}/B/{img['filename']}\"],\n",
    "        'conversations': [],\n",
    "        'type': 6\n",
    "        }\n",
    "    def getNumAnswer(row):\n",
    "        ans = []\n",
    "        road_count = row['change_counts']['road']\n",
    "        building_count = row['change_counts']['building']\n",
    "        if road_count == 0 or row['changeflag'] == 0 :\n",
    "            ans = \"No roads has changed, \"\n",
    "        elif road_count == 1:\n",
    "            ans = \"1 road has changed, \"\n",
    "        else:\n",
    "            ans = f\"{road_count} roads has changed, \"\n",
    "\n",
    "        if building_count == 0 or row['changeflag'] == 0:\n",
    "            ans += \"and no buildings has changed.\"\n",
    "        elif building_count == 1:\n",
    "            ans += \"and 1 building has changed.\"\n",
    "        else:\n",
    "            ans += f\"and {building_count} buildings has changed.\"\n",
    "        return ans\n",
    "    \n",
    "    rslt['conversations'].extend([\n",
    "        {\n",
    "            \"from\": \"human\",\n",
    "            \"value\": \"<image> <image> Please judge whether these two images have changed. Please answer yes or no.\"\n",
    "        },\n",
    "        {\n",
    "            \"from\": \"gpt\",\n",
    "            \"value\": \"Yes\" if img['changeflag'] == 1 else \"No\"\n",
    "        },\n",
    "        {\n",
    "            \"from\": \"human\",\n",
    "            \"value\": \"If changes have occurred, count the number of road and building changes separately.\"\n",
    "        },\n",
    "        {\n",
    "            \"from\": \"gpt\",\n",
    "            \"value\": getNumAnswer(img)\n",
    "        },\n",
    "        {\n",
    "            \"from\": \"human\",\n",
    "            \"value\": \"Based on the above analysis, please describe the changes of these two images in detail.\"\n",
    "        },\n",
    "        {\n",
    "            \"from\": \"gpt\",\n",
    "            \"value\": random.choice(img['sentences']).strip().replace(\" .\", \".\").capitalize()\n",
    "        }\n",
    "    ]\n",
    "    )\n",
    "    instructs.append(rslt)\n",
    "    global_id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91678\n"
     ]
    }
   ],
   "source": [
    "print(len([x for x in instructs]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"LEVIR-MCI-dataset/ChangeChat_instruct_gpt_114k.json\", \"w\") as f:\n",
    "    json.dump(instructs, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Benchmark File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os\n",
    "RAW_JSON_PATH = os.path.expanduser(\"~/autodl-tmp/LEVIR-MCI-dataset/LevirCCcaptions-v2.json\")\n",
    "with open(RAW_JSON_PATH, \"r\") as f: \n",
    "    raw_captions = json.load(f)\n",
    "raw_captions = [row for row in raw_captions if row['filepath'] == \"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jsonlines\n",
    "instructs = []\n",
    "global_id = 100001\n",
    "for img in raw_captions:\n",
    "    for cap in img['sentences']:\n",
    "        rslt = {\n",
    "            'question_id': global_id,\n",
    "            'image': [f\"{img['filepath']}/A/{img['filename']}\", f\"{img['filepath']}/B/{img['filename']}\"],\n",
    "            'answer': cap.replace(\" .\", \".\"),\n",
    "            'category': 'CC'\n",
    "            }\n",
    "        instructs.append(rslt)\n",
    "        global_id += 1\n",
    "        break\n",
    "\n",
    "with jsonlines.open(\"/root/autodl-tmp/LEVIR-MCI-dataset/Test_CC_gt.jsonl\", \"w\") as wfd:\n",
    "    for data in instructs:\n",
    "        wfd.write(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jsonlines\n",
    "instructs = []\n",
    "global_id = 100001\n",
    "for img in raw_captions:\n",
    "    for cap in img['sentences']:\n",
    "        rslt = {\n",
    "            'question_id': global_id,\n",
    "            'image': [f\"{img['filepath']}/A/{img['filename']}\", f\"{img['filepath']}/B/{img['filename']}\"],\n",
    "            'text': \"<image> <image> Please Describe what changes occurred between the two remote sensing images?\",\n",
    "            'changeflag': img['changeflag'],\n",
    "            'category': 'CC'\n",
    "            }\n",
    "        instructs.append(rslt)\n",
    "        global_id += 1\n",
    "        break\n",
    "\n",
    "with jsonlines.open(\"/root/autodl-tmp/LEVIR-MCI-dataset/Test_CC_v3.jsonl\", \"w\") as wfd:\n",
    "    for data in instructs:\n",
    "        wfd.write(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jsonlines\n",
    "instructs = []\n",
    "global_id = 100001\n",
    "for img in raw_captions:\n",
    "    for cap in img['sentences']:\n",
    "        rslt = {\n",
    "            'question_id': global_id,\n",
    "            'image': [f\"{img['filepath']}/A/{img['filename']}\", f\"{img['filepath']}/B/{img['filename']}\"],\n",
    "            'text': \"<image> <image>\\n Have the objects in these two remote sensing images changed? Please answer yes or no.\",\n",
    "            'category': 'CC'\n",
    "            }\n",
    "        instructs.append(rslt)\n",
    "        global_id += 1\n",
    "        break\n",
    "\n",
    "with jsonlines.open(\"/root/autodl-tmp/LEVIR-MCI-dataset/Test_CC_v3_conv_r1.jsonl\", \"w\") as wfd:\n",
    "    for data in instructs:\n",
    "        wfd.write(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "2.7.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
